# Phase 3: The current integration of Large Language Models (LLMs) to augment decision-making

**"What is?": The Challenge of Scale and Cognitive Load**
By the end of Phase 2, the program had successfully scaled to monitoring thousands of assets, validating the FMECA-based data architecture. However, this success introduced new operational challenges. The “What is” state revealed that while the detection of anomalies was automated, the diagnosis and decision-making steps remained heavily dependent on human expertise.
As the number of monitored assets grew, so did the absolute number of alerts. Maintenance teams began facing “alert fatigue,” where the sheer volume of detections—mixed with persistent low-value alarms from rigid Knowledge-Based models—created a bottleneck. Engineers were spending significant time manually validating known issues or correlating diverse data sources (CMMS logs, sensor trends, process conditions) to assess risk. The bottleneck had effectively shifted from seeing the problem to understanding and acting on it efficiently. Furthermore, complex process upsets, such as Liquid Carry Over (LCO), remained difficult to detect with standard vibration or temperature models, leading to significant “missed” opportunities for value generation.

**"What if?": The Generative AI Hypothesis**
To overcome this cognitive bottleneck and deepen the analytical capabilities, the team proposed a new set of “What if” scenarios centered on Generative AI and advanced process modeling:
*   **What if** a Large Language Model (LLM) could act as a “Reliability Co-Pilot,” automatically analyzing sensor trends, cross-referencing them with historical failure modes and documentation, and generating a natural-language diagnosis before a human even opens the alert?
*   **What if** we could move beyond component-level monitoring to model complex process interactions—like Liquid Carry Over (LCO)—that are invisible to single-parameter monitoring but devastating to equipment?
*   **What if** the system could prioritize actions based not just on the probability of failure, but on the context of current operations, effectively filtering the noise for the end user?

**"What wows?": Shape Intel and Deep Learning Validation**
The validation phase (“What wows”) delivered immediate and striking results in 2025. The introduction of **Shape Intel**, an LLM-driven diagnostic module, demonstrated the ability to contextualize alerts instantly. In the fourth quarter of 2025 alone, Shape Intel successfully detected and diagnosed **33% of all confirmed cases**, effectively serving as an autonomous first-line analyst.
Simultaneously, the deployment of a **Multilayer Perceptron (MLP) Neural Network** to predict Liquid Carry Over (LCO) on the MV33 VRU Compression System provided a definitive “wow” moment. The model successfully correlated non-obvious variables—foam index, crude heater temperatures, and defoamer concentration—to predict a process upset that standard vibration monitoring would have missed. This single detection allowed operations to adjust chemical injection proactively, preventing liquid ingress and avoiding an estimated **USD 1.05 million** in potential damage (Case 1.10).

**"What works?": Operational Efficiency and Value Realization**
In the “What works” stage, the focus shifted to rigorously refining the system’s signal-to-noise ratio and operational integration. Through continuous hyperparameter tuning and the strategic retirement of redundant models, the program achieved a **34% reduction in total alarms** in 2025 compared to the previous year, directly addressing the alert fatigue issue.
This efficiency did not come at the cost of coverage; the system delivered **27 confirmed high-impact success cases** in 2025, contributing to **USD 13.64 million** in avoided losses. The integration of GenAI transformed the workflow: instead of engineers starting from a raw data chart, they began their investigation with a pre-synthesized diagnosis, reducing the time from “alert” to “actionable work order” significantly. Phase 3 proved that the next frontier of asset management is not just more data, but synthesized intelligence that empowers faster, more accurate human decision-making.
